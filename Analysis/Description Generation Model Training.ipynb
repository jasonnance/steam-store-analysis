{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains code to train a LSTM RNN on the corpus of all Steam game store long descriptions and generate new descriptions.\n",
    "\n",
    "Based on this blog post: http://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/\n",
    "and this example: https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py\n",
    "\n",
    "Things tried:\n",
    " - 100 char window, 1 char stride (bad results with big/small models) (all spaces or \"toes\")\n",
    " - Cleaned out all but alphanumeric chars and some punctuation\n",
    " - 40 char window, 3 char stride (much better results with small model) (\"and the coanen\")\n",
    " - 60 char window, 3 char stride (better results but a big jump in error around 10th epoch) (\"and_seeens\", \"to\")\n",
    " - don't take out lowercase, use adadelta optimizer, don't skip chars, big seq length, 3 LSTM layers w/ Dropout 0.3 (\"to the start\")\n",
    " - convert multiple spaces to one, drop long/short descriptions, limit to metacritic_review is not null (hopefully finding more homogeneous descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "/home/jason/.pyenv/versions/miniconda3-latest/envs/steam-store-analysis/lib/python3.6/site-packages/theano/gpuarray/dnn.py:135: UserWarning: Your cuDNN version is more recent than Theano. If you encounter problems, try updating Theano or downgrading cuDNN to version 5.1.\n",
      "  warnings.warn(\"Your cuDNN version is more recent than \"\n",
      "Using cuDNN version 6021 on context None\n",
      "Mapped name None to device cuda: GeForce GTX 970 (0000:01:00.0)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import dataset\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db = dataset.connect(os.environ['POSTGRES_URI'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull texts from our database.  Limit the number of descriptions pulled to prevent us from running out of memory (and order randomly so we get a random sample).  Keep only descriptions with metacritic scores to hopefully cut out a lot of the really tiny indie games with broken English in their descriptions.  This biases us toward AAA games, but I think that's fine for the purpose of generating stereotypical game descriptions, and there are still plenty to choose from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "['ABOUT THIS GAME\\nCounter-Strike: Global Offensive (CS: GO) will expand upon the team-based action gameplay that it pioneered when it was launched 14 years ago.\\n\\nCS: GO features new maps, characters, and weapons and delivers updated versions of the classic CS content (de_dust, etc.). In addition, CS: GO will introduce new gameplay modes, matchmaking, leader boards, and more.\\n\\n\"Counter-Strike took the gaming industry by surprise when the unlikely MOD became the most played online PC action game in the world almost immediately after its release in August 1999,\" said Doug Lombardi at Valve. \"For the past 12 years, it has continued to be one of the most-played games in the world, headline competitive gaming tournaments and selling over 25 million units worldwide across the franchise. CS: GO promises to expand on CS\\' award-winning gameplay and deliver it to gamers on the PC as well as the next gen consoles and the Mac.\"']\n"
     ]
    }
   ],
   "source": [
    "description_query = '''\n",
    "WITH filtered_games AS (\n",
    "  SELECT *\n",
    "  FROM game_crawl\n",
    "  WHERE is_dlc = FALSE\n",
    "    AND game_name IS NOT NULL\n",
    "    AND metacritic_score IS NOT NULL\n",
    "),\n",
    "lower_length_limit AS (\n",
    "  SELECT percentile_cont(0.01) WITHIN GROUP (ORDER BY length(long_description)) AS lower_limit\n",
    "    FROM filtered_games\n",
    "),\n",
    "upper_length_limit AS (\n",
    "  SELECT percentile_cont(0.99) WITHIN GROUP (ORDER BY length(long_description)) AS upper_limit\n",
    "    FROM filtered_games\n",
    ")\n",
    "SELECT * \n",
    "FROM filtered_games\n",
    "WHERE length(long_description)\n",
    "  BETWEEN (SELECT lower_limit FROM lower_length_limit)\n",
    "    AND (SELECT upper_limit FROM upper_length_limit)\n",
    "ORDER BY random()\n",
    "LIMIT 1000\n",
    "'''\n",
    "\n",
    "corpus = [r['long_description'] for r in db.query(description_query)]\n",
    "print(len(corpus))\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the distribution of lengths on the descriptions to make sure we didn't get any crazy outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb511b0edd8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD8CAYAAABthzNFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb56c90b978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(corpus).apply(len).plot(kind='hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply cleaning to help the model out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_char_re = re.compile(r'[^-a-zA-Z0-9 !.,?\\n:()]')\n",
    "multi_spaces_re = re.compile(r'(\\s){2,}')\n",
    "\n",
    "def clean_description(description):\n",
    "    filtered_description = bad_char_re.sub('', description)\n",
    "    # Replace two or more spaces with one space\n",
    "    filtered_description = multi_spaces_re.sub(r'\\1\\1', filtered_description)\n",
    "    return filtered_description\n",
    "\n",
    "cleaned_corpus = [clean_description(d) for d in corpus]\n",
    "del corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a mapping of unique chars to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "joined_corpus = '\\n'.join(cleaned_corpus)\n",
    "del cleaned_corpus\n",
    "chars = sorted(list(set(joined_corpus)))\n",
    "print(chars)\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of characters in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1461861\n"
     ]
    }
   ],
   "source": [
    "n_chars = len(joined_corpus)\n",
    "print(n_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of characters in the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    }
   ],
   "source": [
    "n_vocab = len(chars)\n",
    "print(n_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the dataset of input to output pairs encoded as integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1461721/1461721 [00:18<00:00, 80401.33it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1461721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "seq_length = 140\n",
    "step = 1\n",
    "data_x = []\n",
    "data_y = []\n",
    "for i in tqdm(range(0, n_chars - seq_length, step)):\n",
    "    start = i\n",
    "    end = i + seq_length\n",
    "    seq_in = joined_corpus[start:end]\n",
    "    seq_out = joined_corpus[end]\n",
    "    data_x.append([char_to_int[char] for char in seq_in])\n",
    "    data_y.append(char_to_int[seq_out])\n",
    "n_patterns = len(data_x)\n",
    "print(n_patterns)\n",
    "del joined_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the X array to be [samples, time steps, features], normalize, and one-hot encode the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_text_samples(text_samples, n_patterns, seq_length):\n",
    "    return np.reshape(text_samples, (n_patterns, seq_length, 1)) / float(n_vocab)\n",
    "\n",
    "X = transform_text_samples(data_x, n_patterns, seq_length)\n",
    "y = keras.utils.np_utils.to_categorical(data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.LSTM(128, input_shape=(X.shape[1], X.shape[2]), return_sequences=True, implementation=2))\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "model.add(keras.layers.LSTM(128, return_sequences=True, implementation=2))\n",
    "model.add(keras.layers.LSTM(128, implementation=2))\n",
    "model.add(keras.layers.Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "# optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta')\n",
    "\n",
    "checkpoint_path = Path('models', 'weights-improvement-{epoch:02d}-{loss:.4f}.hdf5')\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(str(checkpoint_path), monitor='loss',\n",
    "                                             verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1461632/1461721 [============================>.] - ETA: 0s - loss: 2.9168Epoch 00000: loss improved from inf to 2.91683, saving model to models/weights-improvement-00-2.9168.hdf5\n",
      "1461721/1461721 [==============================] - 1926s - loss: 2.9168  \n",
      "Epoch 2/60\n",
      "1461632/1461721 [============================>.] - ETA: 0s - loss: 2.6051Epoch 00001: loss improved from 2.91683 to 2.60510, saving model to models/weights-improvement-01-2.6051.hdf5\n",
      "1461721/1461721 [==============================] - 1910s - loss: 2.6051  \n",
      "Epoch 3/60\n",
      "1461632/1461721 [============================>.] - ETA: 0s - loss: 2.4457Epoch 00002: loss improved from 2.60510 to 2.44575, saving model to models/weights-improvement-02-2.4457.hdf5\n",
      "1461721/1461721 [==============================] - 1910s - loss: 2.4457  \n",
      "Epoch 4/60\n",
      "1461632/1461721 [============================>.] - ETA: 0s - loss: 2.3315Epoch 00003: loss improved from 2.44575 to 2.33146, saving model to models/weights-improvement-03-2.3315.hdf5\n",
      "1461721/1461721 [==============================] - 1916s - loss: 2.3315  \n",
      "Epoch 5/60\n",
      "1461632/1461721 [============================>.] - ETA: 0s - loss: 2.2422Epoch 00004: loss improved from 2.33146 to 2.24218, saving model to models/weights-improvement-04-2.2422.hdf5\n",
      "1461721/1461721 [==============================] - 1916s - loss: 2.2422  \n",
      "Epoch 6/60\n",
      "1461632/1461721 [============================>.] - ETA: 0s - loss: 2.1742Epoch 00005: loss improved from 2.24218 to 2.17423, saving model to models/weights-improvement-05-2.1742.hdf5\n",
      "1461721/1461721 [==============================] - 1916s - loss: 2.1742  \n",
      "Epoch 7/60\n",
      "1461632/1461721 [============================>.] - ETA: 0s - loss: 2.1187Epoch 00006: loss improved from 2.17423 to 2.11872, saving model to models/weights-improvement-06-2.1187.hdf5\n",
      "1461721/1461721 [==============================] - 1914s - loss: 2.1187  \n",
      "Epoch 8/60\n",
      "1461632/1461721 [============================>.] - ETA: 0s - loss: 2.0730Epoch 00007: loss improved from 2.11872 to 2.07297, saving model to models/weights-improvement-07-2.0730.hdf5\n",
      "1461721/1461721 [==============================] - 1914s - loss: 2.0730  \n",
      "Epoch 9/60\n",
      "1461632/1461721 [============================>.] - ETA: 0s - loss: 2.0327Epoch 00008: loss improved from 2.07297 to 2.03267, saving model to models/weights-improvement-08-2.0327.hdf5\n",
      "1461721/1461721 [==============================] - 1912s - loss: 2.0327  \n",
      "Epoch 10/60\n",
      "1461632/1461721 [============================>.] - ETA: 0s - loss: 1.9938Epoch 00009: loss improved from 2.03267 to 1.99376, saving model to models/weights-improvement-09-1.9938.hdf5\n",
      "1461721/1461721 [==============================] - 1912s - loss: 1.9938  \n",
      "Epoch 11/60\n",
      "1461632/1461721 [============================>.] - ETA: 0s - loss: 1.9572Epoch 00010: loss improved from 1.99376 to 1.95715, saving model to models/weights-improvement-10-1.9572.hdf5\n",
      "1461721/1461721 [==============================] - 1911s - loss: 1.9572  \n",
      "Epoch 12/60\n",
      "1461632/1461721 [============================>.] - ETA: 0s - loss: 1.9249Epoch 00011: loss improved from 1.95715 to 1.92494, saving model to models/weights-improvement-11-1.9249.hdf5\n",
      "1461721/1461721 [==============================] - 1912s - loss: 1.9249  \n",
      "Epoch 13/60\n",
      "1461632/1461721 [============================>.] - ETA: 0s - loss: 1.8997Epoch 00012: loss improved from 1.92494 to 1.89965, saving model to models/weights-improvement-12-1.8996.hdf5\n",
      "1461721/1461721 [==============================] - 1912s - loss: 1.8996  \n",
      "Epoch 14/60\n",
      "1461632/1461721 [============================>.] - ETA: 0s - loss: 1.8758Epoch 00013: loss improved from 1.89965 to 1.87575, saving model to models/weights-improvement-13-1.8757.hdf5\n",
      "1461721/1461721 [==============================] - 1913s - loss: 1.8757  \n",
      "Epoch 15/60\n",
      "1461632/1461721 [============================>.] - ETA: 0s - loss: 1.8547Epoch 00014: loss improved from 1.87575 to 1.85470, saving model to models/weights-improvement-14-1.8547.hdf5\n",
      "1461721/1461721 [==============================] - 1912s - loss: 1.8547  \n",
      "Epoch 16/60\n",
      "1461632/1461721 [============================>.] - ETA: 0s - loss: 1.8349Epoch 00015: loss improved from 1.85470 to 1.83491, saving model to models/weights-improvement-15-1.8349.hdf5\n",
      "1461721/1461721 [==============================] - 1912s - loss: 1.8349  \n",
      "Epoch 17/60\n",
      "1461632/1461721 [============================>.] - ETA: 0s - loss: 1.8166Epoch 00016: loss improved from 1.83491 to 1.81667, saving model to models/weights-improvement-16-1.8167.hdf5\n",
      "1461721/1461721 [==============================] - 1907s - loss: 1.8167  \n",
      "Epoch 18/60\n",
      "1461632/1461721 [============================>.] - ETA: 0s - loss: 1.8001Epoch 00017: loss improved from 1.81667 to 1.80007, saving model to models/weights-improvement-17-1.8001.hdf5\n",
      "1461721/1461721 [==============================] - 1907s - loss: 1.8001  \n",
      "Epoch 19/60\n",
      "1461632/1461721 [============================>.] - ETA: 0s - loss: 1.7851Epoch 00018: loss improved from 1.80007 to 1.78512, saving model to models/weights-improvement-18-1.7851.hdf5\n",
      "1461721/1461721 [==============================] - 1908s - loss: 1.7851  \n",
      "Epoch 20/60\n",
      "1461632/1461721 [============================>.] - ETA: 0s - loss: 1.7708Epoch 00019: loss improved from 1.78512 to 1.77079, saving model to models/weights-improvement-19-1.7708.hdf5\n",
      "1461721/1461721 [==============================] - 1907s - loss: 1.7708  \n",
      "Epoch 21/60\n",
      "1461632/1461721 [============================>.] - ETA: 0s - loss: 1.7577Epoch 00020: loss improved from 1.77079 to 1.75771, saving model to models/weights-improvement-20-1.7577.hdf5\n",
      "1461721/1461721 [==============================] - 1908s - loss: 1.7577  \n",
      "Epoch 22/60\n",
      "1461632/1461721 [============================>.] - ETA: 0s - loss: 1.7449Epoch 00021: loss improved from 1.75771 to 1.74485, saving model to models/weights-improvement-21-1.7449.hdf5\n",
      "1461721/1461721 [==============================] - 1908s - loss: 1.7449  \n",
      "Epoch 23/60\n",
      "1461632/1461721 [============================>.] - ETA: 0s - loss: 1.7338Epoch 00022: loss improved from 1.74485 to 1.73378, saving model to models/weights-improvement-22-1.7338.hdf5\n",
      "1461721/1461721 [==============================] - 1908s - loss: 1.7338  \n",
      "Epoch 24/60\n",
      "1461632/1461721 [============================>.] - ETA: 0s - loss: 1.7237Epoch 00023: loss improved from 1.73378 to 1.72365, saving model to models/weights-improvement-23-1.7237.hdf5\n",
      "1461721/1461721 [==============================] - 1908s - loss: 1.7237  \n",
      "Epoch 25/60\n",
      "1461632/1461721 [============================>.] - ETA: 0s - loss: 1.7130Epoch 00024: loss improved from 1.72365 to 1.71302, saving model to models/weights-improvement-24-1.7130.hdf5\n",
      "1461721/1461721 [==============================] - 1908s - loss: 1.7130  \n",
      "Epoch 26/60\n",
      "1461632/1461721 [============================>.] - ETA: 0s - loss: 1.7038Epoch 00025: loss improved from 1.71302 to 1.70379, saving model to models/weights-improvement-25-1.7038.hdf5\n",
      "1461721/1461721 [==============================] - 1908s - loss: 1.7038  \n",
      "Epoch 27/60\n",
      "1461632/1461721 [============================>.] - ETA: 0s - loss: 1.6948Epoch 00026: loss improved from 1.70379 to 1.69481, saving model to models/weights-improvement-26-1.6948.hdf5\n",
      "1461721/1461721 [==============================] - 1909s - loss: 1.6948  \n",
      "Epoch 28/60\n",
      "1461632/1461721 [============================>.] - ETA: 0s - loss: 1.6866Epoch 00027: loss improved from 1.69481 to 1.68662, saving model to models/weights-improvement-27-1.6866.hdf5\n",
      "1461721/1461721 [==============================] - 1909s - loss: 1.6866  \n",
      "Epoch 29/60\n",
      "1461632/1461721 [============================>.] - ETA: 0s - loss: 1.6788Epoch 00028: loss improved from 1.68662 to 1.67878, saving model to models/weights-improvement-28-1.6788.hdf5\n",
      "1461721/1461721 [==============================] - 1910s - loss: 1.6788  \n",
      "Epoch 30/60\n",
      "1461632/1461721 [============================>.] - ETA: 0s - loss: 1.6707Epoch 00029: loss improved from 1.67878 to 1.67074, saving model to models/weights-improvement-29-1.6707.hdf5\n",
      "1461721/1461721 [==============================] - 1910s - loss: 1.6707  \n",
      "Epoch 31/60\n",
      "1461632/1461721 [============================>.] - ETA: 0s - loss: 1.6639Epoch 00030: loss improved from 1.67074 to 1.66385, saving model to models/weights-improvement-30-1.6639.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1461721/1461721 [==============================] - 1910s - loss: 1.6639  \n",
      "Epoch 32/60\n",
      "1461632/1461721 [============================>.] - ETA: 0s - loss: 1.6566Epoch 00031: loss improved from 1.66385 to 1.65665, saving model to models/weights-improvement-31-1.6567.hdf5\n",
      "1461721/1461721 [==============================] - 1903s - loss: 1.6567  \n",
      "Epoch 33/60\n",
      " 227584/1461721 [===>..........................] - ETA: 1608s - loss: 1.6466"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8ed647879db6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/jason/.pyenv/versions/miniconda3-latest/envs/steam-store-analysis/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    854\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/jason/.pyenv/versions/miniconda3-latest/envs/steam-store-analysis/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jason/.pyenv/versions/miniconda3-latest/envs/steam-store-analysis/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jason/.pyenv/versions/miniconda3-latest/envs/steam-store-analysis/lib/python3.6/site-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jason/.pyenv/versions/miniconda3-latest/envs/steam-store-analysis/lib/python3.6/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jason/.pyenv/versions/miniconda3-latest/envs/steam-store-analysis/lib/python3.6/site-packages/theano/scan_module/scan_op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[1;32m    987\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[1;32m    988\u001b[0m                  allow_gc=allow_gc):\n\u001b[0;32m--> 989\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jason/.pyenv/versions/miniconda3-latest/envs/steam-store-analysis/lib/python3.6/site-packages/theano/scan_module/scan_op.py\u001b[0m in \u001b[0;36mp\u001b[0;34m(node, args, outs)\u001b[0m\n\u001b[1;32m    976\u001b[0m                                                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m                                                 \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m                                                 self, node)\n\u001b[0m\u001b[1;32m    979\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X, y, epochs=60, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = Path('models', 'weights-improvement-31-1.6567.hdf5')\n",
    "model.load_weights(str(filename))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adadelta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a reverse mapping for ints to chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate predictions from a seed sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "Michael Thorton will carry consequences for his future and the fate of the world.\n",
      "ABOUT THIS GAME\n",
      "The critically-acclaimed and award-winning\n",
      "\n",
      "\n",
      "Result (diversity 0.05):\n",
      " and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and ceauh and ceauh in the complete and ceauh in the complete and the cester of the game in the complete and cester cetter cetter cetter complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and complete and comp\n",
      "\n",
      "\n",
      "Result (diversity 0.1):\n",
      "lete and ceauh and control of the many of the game in the complete and cester cetter cetter cetter cetter cetter ceautiful and complete and complete and ceauhs and complete the world of the game in the complete and the competitive sole of the most and complete and ceauh and cester and ceauh and the world of the world of the game to the complete and strategy game with the castle to the story of the competitive mode. \n",
      "The game is a strategy game that is a strategy game is a strategy game in the fame of the game is a strategy game with a series of an interaction of the many of the many of the game in the complete and additional combat system that is the complete and the competitive story of the competitive story of the most adventure to the world of the most experience.\n",
      "\n",
      "Aombat and the game is a strategy game that is the fame of the game in the complete and the many of the complete and the combat system that is the strategy game with a seal- and the most and cester and cester and complete\n",
      "\n",
      "\n",
      "Result (diversity 0.2):\n",
      " the game in the cester can be all the best start and experience the streets of the most powerful story in the campaign in a strategy game with a first person shooter that will experience the story of the game and the combat system that in the world of the game world.\n",
      "\n",
      "Features:\n",
      "The game where you can be a strategy game that has been into the cattle of the game in the complete and ceauhs and competitive story and ceauh in the combat system.\n",
      "\n",
      "An additional combat tystem and competitive experience and ceauh in the content of the world of the most powerful combat to the competitive mew complete and the combat struival in the competitive story of the game to be a strategy game to ce the strategy game mode with a complete and complete story.\n",
      "\n",
      "Aotnte your friends and interactive and strategy and the street that will be a tnique ways of the fame in the cestroy and more than ever with a complete and cester complete and complete and ceauhs and cester and ceauh in the most powerful story of the \n",
      "\n",
      "\n",
      "Result (diversity 0.5):\n",
      "Sastical and exterience. Aace on the hnseroation of Mensann the world of uhe same of ship is from the stars with the strategy and the crings of the most adventure that like a syo genre and one of the three first person strpyiss of case and counter the cays of as an experience of the cattle. \n",
      "Be hs a gortily of the combat that can be a mew way of the planet with the dangerous game is more than ever ho the fame of eifht platformer campaign, And a three stune through the cam stand of an increase and play, destroyed and an ancient fight for the ancient realisy and the story in the famaxy, as commectinn of the World of an exen domprl. The game world of the combat sypes of a more for features the geroe and the land realmy how to the the story of the eark and power of the beautiful shoulators to explore the game aeventure to the modern ceauh. ABOUT THIS GAME\n",
      "Io the country of a challenging and competitive and uay to the experience experience with a complexe story in a sinulation of the game. \n",
      "\n",
      "\n",
      "Result (diversity 0.75):\n",
      "\n",
      "Bdad Sesron of a first-person shoulations of thrans set on a masser of puest to breate a ceautiful wide-ounring and more your purchasable the cootdnt gor your surpor beaome characters and combat and means adds from eefp from the cousse of Gorcer sells. . Ao in she cartiving adventure through the riilt iu is ce mocie provides on the bouh. \n",
      "Uhe friends actoss the story is an inttruted from recelyion, leaders, and celor,each of interactive, rame of all that becore your own offers aboul lose moder! as uhe course terration of the Bett Hrosr in the soldier before recoudr the powerful combat. The fame maner in the colprser down in the beautiful opw a strenle cnmfc and explar on the Aead\n",
      "with enemies uitually domland the hods. \n",
      "CQST SEATSES \n",
      " Dancy prove and clocked with faigllar, if soecial style and unique characters grow anorser the world hame is time cefind your dhpice to inporative mew gour modations,\n",
      "Fvnt objects and she Crcatmvaathe Bater hs a rtrategy comtrol of his target through the\n",
      "\n",
      "\n",
      "Result (diversity 1.0):\n",
      " rocaming minutes of hunabioe of puestions. Co elianced accesbtie gomd, hs pessesanteatiog eectorl HIC tragn, ouel battleshass amd rtahe of the Eark inrelse,eissie realist, \n",
      "Tie kine odoee, you  Saklted to see( Uhe olll,scwe pn his iss binaclic piwer commedtic dungeons and beaut or a nap, napu powerous tnanniine battles weapons, docu woull dhscover the girst welliigsies\n",
      "and all puzzle player is. Whyhtu and this is stre bomtsoe how their pwn wariedts, Lrs a profressenu 40 tole ie exen, Nor ie is surnor three ase pani. Cfattefcsh combat with share wish mou into Mhe,Iames, b mew reason, Mey Features\n",
      "Hxperrive Meeective:\n",
      "Hn eifhts and bulfc on the wears alone- raz as diacr is as the most adventure while fiatou moder. but become uhe domcations and play as is words\n",
      "or into the giost.\n",
      "Pream thrilling all famtast inttodutes your seal tp, and rrouice. Av you in on ce sells and soace players. Whuh bm EIoge-ma the gring experience uhe feat shrough the chpem and main and save the stbrt hunce and b\n",
      "\n",
      "\n",
      "Result (diversity 1.2):\n",
      "egore siared. Shis senv newhls you in your freeme intow thooe,.she teries\n",
      "of their ower 60 -Vie rag:  Oow Cegtions, timln ceatuieign, gelrsary dtimiie anopseru amd afainst qesstne,gasdtny combat and gighless catnefers\n",
      " Fimpedd Iohv. each with a dream dome bevigo team inteliers outhoys famietic eruinge lodsme fuents  Fmmostanibges is a thrle tracks agtt) and dme-digdlony reourations Cvpacirabke Wnrayhikase Bhius.\n",
      "Eestacte nulgen rauage game in ouerlors gvtur in Hirwan slowchn thder. Heaturess amc Sizehnlkeitinn off, lefe uhe Kimc Slay as ited- fatty ouber rangemized wecponly colpsser ciawict: much uobielep inhlrtaoied by Sidtx, particlea her acout awnising lersesicle in she Oans-and Vuory: The course and challenging bailityicsliny druieicl rtecition and itnv iumYnit, Snlock in daley, encumnuary ploster reou prsategy -uhagots twrhs and exel dirtence 20 !vith new rowarion mearay twopor,- Tp sinnle is clearsmy tsorrU\n",
      "your holds including incoeas - The lovn astuuni 2jdrmiehing fame gas she \n"
     ]
    }
   ],
   "source": [
    "start = np.random.randint(0, len(data_x)-1)\n",
    "pattern = data_x[start]\n",
    "print(\"Seed:\\n{}\".format(''.join([int_to_char[value] for value in pattern])))\n",
    "num_generated_chars = 1000\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "for diversity in (0.05, 0.1, 0.2, 0.5, 0.75, 1.0, 1.2):\n",
    "    generated_str = ''\n",
    "\n",
    "    for i in range(num_generated_chars):\n",
    "        x = transform_text_samples(pattern, 1, len(pattern))\n",
    "        prediction = model.predict(x, verbose=0)\n",
    "        index = sample(prediction[0], temperature=diversity)\n",
    "        result = int_to_char[index]\n",
    "        seq_in = [int_to_char[value] for value in pattern]\n",
    "        generated_str += result\n",
    "        pattern.append(index)\n",
    "        pattern = pattern[1:]\n",
    "\n",
    "    print(\"\\n\\nResult (diversity {}):\\n{}\".format(diversity, generated_str))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
